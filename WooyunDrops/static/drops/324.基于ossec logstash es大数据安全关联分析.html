<main class="main-container ng-scope" ng-view=""><div class="main receptacle post-view ng-scope"><article class="entry ng-scope" ng-controller="EntryCtrl" ui-lightbox=""><header><h1 class="entry-title ng-binding">基于ossec logstash es大数据安全关联分析</h1><div class="entry-meta"><a target="_blank" class="author name ng-binding">winsyk</a> <span class="bull">·</span> <time title="2014/08/15 10:58" ui-time="" datetime="2014/08/15 10:58" class="published ng-binding ng-isolate-scope">2014/08/15 10:58</time></div></header><section class="entry-content ng-binding" ng-bind-html="postContentTrustedHtml"><p></p><h2>0x00 前言：</h2><hr><p>对于大数据我相信大多数人都不陌生，特别现在是在大数据时代，当下流行的技术很多人都可以朗朗上口比如hadoop、hbase、spark、storm，那么在数据收集中，是否有好的解决办法来帮助企业进行安全管理及策略分析呢，笔者搜索了很多资料，通过自己的实践分享一篇我对大数据日志分析及处理的见解，本篇技术是基于logstash elasticsearch、redis结合ossec来做的开源方案。 在《无处可藏》中斯诺登提到NSA对网络及数据收集的原则是收集一切，在企业安全上也需要做到如此，众所周知安全的风险来自于边界，黑客也会挑一些比较边缘的业务进行入侵，但这些东西我们都没记录但对于后续的应急响应和入侵检测来说就无从谈起，所以在企业内做大数据的原则也是“收集一切”。 开篇提到的这些主要是为了下文做铺垫，本文基于系统安全日志来做收集及处理，希望能给大家提供一些思路，整体为开源技术，屌丝安全的本质是“快”，当前社会唯快不破。</p><h2>0x01: 技术架构： 使用到的工具如下：</h2><hr><blockquote><p>Ossec（事件源、alert源） Logstash （日志收集、分割日志) Elasticsearch (全文搜索) Kibana3 (日志展现) Redis（用于数据存储，防止数据丢失）</p></blockquote><p>使用该方案好处：opensource， 不方便处：资料较少，尤其是对Kibana</p><h2>0x02：实施方案：</h2><hr><p>关于如何安装，请参考： https://app.yinxiang.com/shard/s21/sh/f4e62686-16ef-4549-beb1-c5124b232df6/f538a1ea304ff4191acf494a1a1bd4f9</p><h2>0x03：技术实践：</h2><hr><p><strong>1、 系统日志收集：</strong></p><p>操作系统日志收集可以采取syslog、rsyslog等技术，本文使用syslog主要对于收集日志安全日志，日志内容范围为/var/log/secure，、/var/log/lastlog等，/var/log/secure内基于用户的登录失败、登录异常、是否从白名单ip登录等都可以审计到，然后来做关联分析，更多的维度需要各位看官自己去发现和探索，本文不深入讲解。</p><p>日志收集作用： 应用场景：系统安全日志薄弱在黑客防御过程中，如果日志被删除，syslog服务被暂停，这些都会对系统入侵分析造成麻烦，难以追溯。</p><p><strong>2、 入侵检测系统ossec：</strong></p><p>Syslog日志进来后不能不做分析，如果不分析，数据就不会被用活只是死数据，这里用到开源ids系统，Ossec，Ossec大家或许并不陌生，ossec 支持2种模式：1、ossec agent； 2、基于syslog方式对日志做收集，通过客户端配置syslog将日志传送到ossec server，然后ossec server会通过对分析日志进格式化处理规则解析，判断异常并且对其做处理，比如写入数据库，触发告警，如图1为处理日志过程。</p><p><img alt="enter image description here" img-src="a25cf8e9ac7d4e7a121f4c098de27a1b1ff9389e.jpg"></p><p>如图2为ossec整个工作过程：</p><p><img alt="enter image description here" img-src="093a31b2578a642aff241125b26a7d6b39e42392.jpg"></p><p><strong>3、 日志集中化管理 logstash:</strong></p><p>Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索），您可以使用它。说到搜索，logstash带有一个web界面，搜索和展示所有日志，但因为logstash的管理界面不如kibana美观，这里使用Kibana做日志展现。 我安装的logstash版本为:logstash-1.2.2-flatjar.jar,通过命令:</p><pre><code>java -jar logstash-1.2.2-flatjar.jar agent -f logstash_agent.conf
</code></pre><p>将logstash启动，logstash_agent.conf内容如下图：</p><p><img alt="enter image description here" img-src="16533a7cbcedda99eb69c95129a87f0b59602d79.jpg"></p><p>对上图logstash内容进行分解，它一共做了这些事。</p><ol><li>通过读取ossec alert log,将数据读取到logstash agent。</li><li>Logstash判断事件源是否为ossec，如果是则对其进行分割字段；</li><li>将处理后的logstash日志写入到redis；</li><li>使用redis的目的是为了将logstash读取的日志缓存到redis内，防止数据丢失。</li></ol><p><strong>4、 全文检索 elasticsearch：</strong></p><p>ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 在本文中ElasticSearch主要的作用，通过es读取logstash内ossec日志进行全文检索，方便后续日志展现及搜索，es默认端口为9200，成功开启es后会提示如下：</p><p><img alt="enter image description here" img-src="cfa802be41f7da9a90b13188e82f591ff0e2223f.jpg"></p><p>ElasticSearch启动后可以通过访问http://127.0.0.1:9200来查看es工作是否正常，出现如下数据证明es正常工作 9300端口主要用于和es集群通信发数据。</p><pre><code>{
  "status" : 200,
  "name" : "N'Gabthoth",
  "version" : {
    "number" : "1.2.2",
    "build_hash" : "9902f08efc3ad14ce27882b991c4c56b920c9872",
    "build_timestamp" : "2014-07-09T12:02:32Z",
    "build_snapshot" : false,
    "lucene_version" : "4.8"
  },
  "tagline" : "You Know, for Search"
}
</code></pre><p>通过读取之前写入到redis里的数据，将redis内数据写入到es里，如下配置实现：</p><pre><code>input {
    redis 
    {
    host =&gt; "127.0.0.1"
    data_type =&gt;"list"
    port =&gt; "6379"
    key =&gt; "logstash"
    type =&gt; "ossec"
    }
}

output {
stdout { codec =&gt; rubydebug }
 if [type] == "ossec" {
   elasticsearch {
     host =&gt; "127.0.0.1"
     port =&gt; "9300"
     #cluster =&gt; "ossec"
     index =&gt; "logstash-ossec-%{+YYYY.MM.dd}"
     index_type =&gt; "ossec"
     template_name =&gt; "template-ossec"
     template =&gt; "/usr/local/share/logstash/elasticsearch_template.json"
     template_overwrite =&gt; true
        }
   }
}
</code></pre><p><strong>5、 日志展现：</strong></p><p>既然已经将上述工作都做到位了，那么需要有界面来展现劳动成果及后续进行日志分析，这里使用kibana来做展现，关于kibana各位请自行搜索，我只简单说下我的理解，它的资料很少，笔者在学习过程中也是一路摸索，推荐大家使用这个dashboard来展现日志，下载地址：https://github.com/magenx/Logstash/blob/master/kibana/kibana_dashboard.json <strong>6、 结果展现：</strong></p><p><img alt="enter image description here" img-src="a90d1e94a9be79e66e9fd91cbdf5c340dac45284.jpg"></p><p><img alt="enter image description here" img-src="6601c171e976f26b14b4028f816d8d60ea2e94dd.jpg"></p><p><strong>6.1、 结合Ossec应用场景：</strong></p><p>举例，我们在日常的运维环境中会有常见的登录事件，并且也会限制一些ip是否能登录该主机，在ossec内我们定制一条规则来判断是否有入侵者使用其他ip进行登录。 在ossec里我们可以定制一条规则在sshd_rules.xml中，规则如下：</p><pre><code>&lt;rule id="5739" level="10"&gt;
   &lt;if_sid&gt;5700&lt;/if_sid&gt;
   &lt;group&gt;authentication_failure&lt;/group&gt;
   &lt;srcip&gt;!10.10.2.1&lt;/srcip&gt;
   &lt;description&gt;not come from 10.10.2.1&lt;/description&gt;
   &lt;/rule&gt;
&lt;/group&gt;
</code></pre><p>if_sid是匹配syslog,sshd，如下规则：</p><pre><code>&lt;!-- SSHD messages --&gt;
&lt;group name="syslog,sshd,"&gt;
  &lt;rule id="5700" level="0" noalert="1"&gt;
    &lt;decoded_as&gt;sshd&lt;/decoded_as&gt;
    &lt;description&gt;SSHD messages grouped.&lt;/description&gt;
&lt;/rule&gt;
</code></pre><p>如果有用户触发到该规则，kibana会展现告警如下：</p><p><img alt="enter image description here" img-src="b05dbe5a9ff88fec3650a048ea708c80aec8dfe0.jpg"></p><h2>0x04：</h2><hr><p>借用一句话，安全这个东西就是这样的，你遇到的我没遇到过，我遇到的你可能也没有遇到过，其实只要一说，大家就都明白了。 ” 希望此文对你有帮助，谢谢！</p><p></p></section></article><div class="entry-controls clearfix"><div style="float:left;color:#9d9e9f;font-size:15px"><span>&copy;乌云知识库版权所有 未经许可 禁止转载</span></div></div><div class="yarpp-related"><h3>为您推荐了适合您的技术文章:</h3><ol id="recommandsystem"><li><a href="http://drops.wooyun.org/tips/12673" rel="bookmark" id="re1">Elasticsearch集群的备份与恢复</a></li><li><a href="http://drops.wooyun.org/papers/5107" rel="bookmark" id="re2">ElasticSearch Groovy脚本远程代码执行漏洞分析（CVE-2015-1427）</a></li><li><a href="http://drops.wooyun.org/tips/1951" rel="bookmark" id="re3">渗透技巧之SSH篇</a></li><li><a href="http://drops.wooyun.org/tips/8129" rel="bookmark" id="re4">浅谈Elasticsearch的AAA (I)</a></li></ol></div><div id="comments" class="comment-list clearfix"><div id="comment-list"><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">CHENGPENG1144</span> <span class="reply-time">2016-06-17 15:41:58</span></div><p></p><p>能把logstash_agent.conf文件共享一下吗？谢谢了，<a class="__cf_email__" href="/cdn-cgi/l/email-protection" data-cfemail="0c3538353f353a3a35394c7d7d226f6361">[email&#160;protected]</a></p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">axot</span> <span class="reply-time">2016-03-09 17:02:46</span></div><p></p><p>很好用的样子 就是配置起来有点累人</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">kulo</span> <span class="reply-time">2016-02-24 09:56:23</span></div><p></p><p>@xysky 何工，这套玩意最重要是免费啊</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">r0ots</span> <span class="reply-time">2016-02-23 14:32:46</span></div><p></p><p>简介的好简单</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">wangy3e</span> <span class="reply-time">2015-04-13 18:04:17</span></div><p></p><p>已破解~~~</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">wangy3e</span> <span class="reply-time">2015-04-13 18:03:47</span></div><p></p><p>哈哈</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">winsyk</span> <span class="reply-time">2015-01-16 20:02:28</span></div><p></p><p>:) 好久不联系</p><p>archsight 同事和我提过不过我没详细使用过，不知道咋样。<br>关联分析，我到觉得是事件驱动，看事件来决定模型如何，这点我做的也不是很好。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">xysky</span> <span class="reply-time">2015-01-14 17:42:37</span></div><p></p><p>winsky，好久未联系啊。<br>商业公司考虑开源的会少一些，这些基本的功能在arcsight都有，采个syslog做个case是easy easy，关键是关联分析目前没看到做的非常好的。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">vf3ng</span> <span class="reply-time">2014-09-04 14:08:11</span></div><p></p><p>在用kibana3做展现时，表示看不到post数据，求解。。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">winsyk</span> <span class="reply-time">2014-08-18 14:20:06</span></div><p></p><p>splunk，每天500M，不够用</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">小新</span> <span class="reply-time">2014-08-18 14:06:07</span></div><p></p><p>splunk 不是免费的吧</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">陈先生在20003</span> <span class="reply-time">2014-08-18 12:59:42</span></div><p></p><p>为什么不用splunk，完全可以替换上面的Logstash，Elasticsearch，Kibana3</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">jymsy</span> <span class="reply-time">2014-08-17 18:36:48</span></div><p></p><p>每天上G的日志用elasticsearch存，内存受不了。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">Lee Swagger</span> <span class="reply-time">2014-08-16 10:41:52</span></div><p></p><p>From BAT?</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">疯子</span> <span class="reply-time">2014-08-16 09:00:22</span></div><p></p><p>赞，CZ不要乱喷哦，感谢LZ分享！</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">winsyk</span> <span class="reply-time">2014-08-15 14:03:57</span></div><p></p><p>没研究过flumed</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">zj1244</span> <span class="reply-time">2014-08-15 14:00:55</span></div><p></p><p>lz，小白一个，问个问题。flume和Logstash都是日志收集的？有什么区别么？flume-ng+Kafka+Storm+HDFS这个和文中说的那套系统有什么优劣么？</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">winsyk</span> <span class="reply-time">2014-08-15 13:26:01</span></div><p></p><p>很多人在意标题，我想说不要在意这些细节，里面的东西自己不深挖是不会理解的。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">周鸿祎</span> <span class="reply-time">2014-08-15 13:20:25</span></div><p></p><p>我看着标题应该叫 3个开源工具的简介</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">winsyk</span> <span class="reply-time">2014-08-15 12:36:01</span></div><p></p><p>大数据是技术，不是指数据大，关联分析是把事件关联，具体的东西暂时不方便写，先酱油个，算是搭个框架，具体个人如何认为，那是自己事。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">X,D</span> <span class="reply-time">2014-08-15 11:47:42</span></div><p></p><p>我顶一个，ossec这么玩才能玩好，批量部署一堆坑。</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">xcl0ud</span> <span class="reply-time">2014-08-15 11:47:36</span></div><p></p><p>楼主用心分享先赞一个！<br>但是请问：大数据呢？！关联呢？！分析呢？！<br>是不是有点标题党了啊</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">Draycen</span> <span class="reply-time">2014-08-15 11:32:44</span></div><p></p><p>不觉明历</p><p></p></div></div><div class="note-comment"><img class="avatar" alt="30" src="http://wooyun.b0.upaiyun.com/wooyun_job/avatar/default.png"><div class="content"><div class="comment-header"><span class="author-link">PgHook</span> <span class="reply-time">2014-08-15 11:02:38</span></div><p></p><p>牛逼！！！！</p><p></p></div></div></div></div></div></main>